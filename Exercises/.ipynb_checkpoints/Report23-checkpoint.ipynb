{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color  Histogram\n",
    "We additionally use individual color channel histogram information, breaking it into **32 bins** within **(0, 256) range**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For definition of color histogram check `lesson_functions.py >> color_hist function` (lines 34-42)\n",
    "\n",
    "> For usage of color histogram in extracting features check `lesson_functions.py >> extract_features function` (line 76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Histogram\n",
    "For spatial information we simply resize the image to 32×32 and flatten to a 1-D vector.\n",
    "> For definition of spatial histogram check `lesson_functions.py >> bin_spatial function` (lines 26-30)\n",
    "> For usage of color histogram in extracting features check `lesson_functions.py >> extract_features function` (line 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FeatureExtractor` (To Do)\n",
    "The code for feature extraction which combines all these features can can be found \n",
    "> For implementation details check `lesson_functions.py >> extract_features function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifier for detecting cars\n",
    "Since this a classical machine learning problem i.e., classification, we chose Linear SVC (`sklearn` implementation), using feature extractor described above. Before training the data, data is scaled using 'Standard Scaler' so that one feature doesn't dominate any other features. Then data is split into training and validation data using `sklearn`'s `train_test_split`. Since training the classifier can be time consuming task, training task is performed once and classifier is stored in python pickle files. When car_classifier class is instantiated, the parameters for the classifier is loaded from python pickle files.\n",
    "\n",
    "> For implementation details check `car_classifier.py >> car_classifier classs>> train_classifier function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame segmentation\n",
    "I use a sliding window approach described in the udacity course which allowed for different scaling, overlap. Different scaling is useful because we can approximate vehicle size we expect in different frame regions, which makes searching a bit easier.\n",
    "\n",
    "### Image here:\n",
    "Since frame segments must be of various size, and we eventually need to use 64×64 regions as a classifier input, I decided to simply scale the frame to various sizes and then scan them with a 64×64 window. \n",
    "\n",
    "> For implementation details check `find_cars function` inside 'VehicleTracker' class under vehicletracker.py (lines 107-143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Merging segmented detections\n",
    "Using find_Cars we get list of bounding boxes where classifier found regions which were coinciding with features of car. However, we can notice from the image below here. There is large overlap between multiple boxes for single object.\n",
    "Also, in some images/frames of videos we found spurious detections/outliers.\n",
    "\n",
    "Inorder to solve the above mentioned problems, we can create a heatmap to detect overlapping regions. \n",
    "Also, to reject outliers we look at last N frames (N is chosen as 10) and objects which are consistent in some of the frames. To summarize, since there are multiple detections on different scales and overlapping windows, we need to merge nearby detections. In order to do that we calculate a heatmap of intersecting regions that were classified as containing vehicles. To store last N frame `dequeue` container is used inside HeatMapper class.\n",
    "After merging heatmaps from multiple scales and multiple frames, we threshold the heatmap. Then we use `label()` function from `scipy.ndimage.measurements` module to detect individual groups of detections, and calculate a bounding rect for each of them. These new bounding boxes are filtered bounding boxes using merge and threshold heatmap technique.\n",
    "\n",
    "> For implementation details check `HeatMapper.py >> HeatMapper Class >> computeHeatMapN' function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "Using the techniques mentioned in above sections, we were able to detect vehicles on the road. The `process` function in VehicleTracker class is used to process images from videos. \n",
    "\n",
    "The total pipeline code is at /Code/MainCode.ipynb The final video of the pipeline implementation can be watched here:\n",
    "https://youtu.be/BMUABwRbmZE\n",
    "\n",
    "> For summary of pipeline check `VehicleTracker.py >> Vehicle Tracker Class >> process' function`\n",
    "\n",
    "This was a great project experience. Eventhough, the current code works fine for the video under test, it is slow in it's performance. The performance of the code can be optimized lot more as all the features might not be required.Also, more tuning needs to be done so that the pipeline is robust to varying lighting conditions. \n",
    "The neat thing I learned here is how car is detected as it's scale changes. We found cars which are father/closer & smaller by scaling up/down the region of search. This gave intuition as why were doing pooling a.k.a scaling in deep learning. I am curious to see how other techniques such as deep learning work here.\n",
    "\n",
    "I have heard of HOG, Classifier etc., before however it was wonderful experience to code them and get intuition for the techniques in this project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
